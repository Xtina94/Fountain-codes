\subsection{The decoding process}
We can look at the quality of the coding scheme by analyzing the performance of the decoding process under different points of view, from the finite lenght analysis of the error probability \cite{Karp2004}, to the analysis of the success probability and the overhead dimension for a small number of packets $N$ \cite{Hyytia2007}, to the opposite analysis with a high $N$ and another decoding technique \cite{Lu}.

\subsubsection{Error probability for the \gls{bp} decoder}
In \cite{Karp2004}, the authors outline a method for calculating the success probabilty in the case of the \gls{bp} decoder, which provides for them a much more efficient decoder than the classical \textit{Gaussian elimination} \cite{Shokrollahi2006}. The \gls{bp} decoder performs the following steps until either all the input symbols have been recovered or until no output symbols of degree one are present in the graph. At each step of the algorithm, the decoder identifies a degree-one output symbol: if not all the input symbols have been recovered yet but none exists,a decoding failure is reported; otherwise, the value of the output symbol of degree one recovers the value of its unique neighbor among the input symbols. Once this input symbol value is recovered, its value is added to the values of all the neighboring output symbols, and the input symbols and all edges emanating from it are removed from the graph. So, as the \gls{bp} decoder recovers one input symbol at each step, following Lubyâ€™s notation, we call the set of output symbols of reduced degree one the \textit{output ripple} at step \textit{i} of the algorithm. \cite{Shokrollahi2006}

The start in \cite{Karp2004} is from defining the shape of the distribution $\Omega = (\Omega_1,\dots,\Omega_k)$, chosen on the set $\{1,\dots,k\}$, and which induces a distribution $\mathcal{D}$ on $\mathbb{F}_2^k$ we can choose our output symbols from. An LT code so described has parameters $(k,\Omega(x))$, with $x$ being the input symbol considered and $\Omega(x) = \Omega_1x+\Omega_2x^2+\dots+\Omega_kx^k$ is the generating function of the distribution. The importance of the success probability of the decoder comes from the fact that the number $n$ of encoding symbols to which we apply the \gls{bp} strictly depends on it and the output degree distribution.

Later on in the work, the authors present a recursive approach centered on the probability distribution generating function $P_u(x,y)$, whose bit-complexity is shown to be proportional to $O(n^3\log^2(n)\log\log(n))$ ($n$ is the number of collected out symbols of the LT-code). The computation is therefore efficient and reveals to be useful also to derive recursions for the expected number of output symbols of degree $1$ at each stage $u$ as:
\begin{equation}
  R(x) = x\Omega'(1-x)+x\ln(x) \qquad \text{for } x = \frac{u}{k}
\end{equation}
