\subsection{Performance analysis of BER in a BIMSC}
This class of codes has been widely used in several scenarios since it was first designed, with the convenient approach of looking at the boundary conditions for the fountain codes and expanding them to the case of Raptor codes. In particular, in \cite{Etesami2006} Etesami \textit{et al.} investigate the supposition that, from the success of Fountain codes for erasure channels, a similar result can be expected for other binary symmetric channels and so also for Raptor codes. In the work, the authors show how some of the properties of LT- and Raptor codes over the erasure channel can be transferred onto any \gls{bimsc}. In some details, they consider the degree distribution optimized for the erasure channel and study the residual \gls{ber} of the decoder in the case of \gls{bp} algorithm being applied and this as a function of the overhead chosen. In the paper there are some major emphases on the structure of the degree distribution - which now needs to be used from the perspective of edges - on the channel structure, considering binary antipodal signaling, and on the feasibility of the classical Gaussian approximation technique for simplifying the density of the messages passed at each round to the \gls{bp} algorithm.

Concerning the simulations, these were performed for optimized degree distributions with respect to the \gls{bec}, as already described in \cite{Shokrollahi2006}. The experiments in \cite{Etesami2006} use the output distribution
\begin{align}
  \Omega(x) =&0.008x + 0.494x^2 + 0.166x^3 + 0.073x^4 + 0.083x^5 + 0.056x^8\\
             &+ 0.037x^9 + 0.056x^{19} + 0.025x^{65} + 0.003x^{66}
\end{align}
In the performed experiments, the focus was on the \gls{ber} at the end of the decoding process. The graphs in Fig2 in \cite{Etesami2006} show the advantage of Raptor Codes over LT-codes clearly, and it is observed that for a small average degree the LT-codes exhibit a bad error floor behavior. Nevertheless there is still room for improvement through the addition of a technique called \textit{Gaussian approxhimation}: the method approxhimates message densities as a Gaussian, or a mixture of them, in such a way that it is possible to collapse the density of the messages passed to the \gls{bp} algorithm to a single-variable recursion for the mean of a Gaussian.
